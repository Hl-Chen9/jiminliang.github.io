@article{WeiChen_2023_Sensors,
 abstract = {The resolution of feature maps is a critical factor for accurate medical image segmentation. Most of the existing Transformer-based networks for medical image segmentation adopt a U-Net-like architecture, which contains an encoder that converts the high-resolution input image into low-resolution feature maps using a sequence of Transformer blocks and a decoder that gradually generates high-resolution representations from low-resolution feature maps. However, the procedure of recovering high-resolution representations from low-resolution representations may harm the spatial precision of the generated segmentation masks. Unlike previous studies, in this study, we utilized the high-resolution network (HRNet) design style by replacing the convolutional layers with Transformer blocks, continuously exchanging feature map information with different resolutions generated by the Transformer blocks. The proposed Transformer-based network is named the high-resolution Swin Transformer network (HRSTNet). Extensive experiments demonstrated that the HRSTNet can achieve performance comparable with that of the state-of-the-art Transformer-based U-Net-like architecture on the 2021 Brain Tumor Segmentation dataset, the Medical Segmentation Decathlon&rsquo;s liver dataset, and the BTCV multi-organ segmentation dataset.},
 article-number = {3420},
 author = {Wei, Chen and Ren, Shenghan and Guo, Kaitai and Hu, Haihong and Liang, Jimin},
 doi = {10.3390/s23073420},
 issn = {1424-8220},
 journal = {Sensors},
 number = {7},
 pubmedid = {37050479},
 title = {High-Resolution Swin Transformer for Automatic Medical Image Segmentation},
 url = {https://www.mdpi.com/1424-8220/23/7/3420},
 volume = {23},
 year = {2023}
}
